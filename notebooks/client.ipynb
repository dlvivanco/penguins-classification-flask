{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b7eb61",
   "metadata": {},
   "source": [
    "# 1: Importaci√≥n y Configuraci√≥n\n",
    "\n",
    "En este primer paso, importamos la librer√≠a requests, que act√∫a como nuestro \"navegador\" web para enviar datos, y definimos la direcci√≥n donde nuestro servidor Flask est√° escuchando (localhost puerto 9696). Tambi√©n listamos los identificadores de los 4 modelos que definimos en la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "872b19fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.4-cp314-cp314-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp314-cp314-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   ---------------------------------------- 5/5 [requests]\n",
      "\n",
      "Successfully installed certifi-2025.11.12 charset_normalizer-3.4.4 idna-3.11 requests-2.32.5 urllib3-2.6.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\leox_\\anaconda3\\envs\\cas-practic\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# Instalar requests usando pip dentro de Jupyter\n",
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81a0ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente configurado para conectar a: http://localhost:9696/predict/\n",
      "Modelos a testear: ['lr', 'svm', 'dt', 'knn']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# 1. Configuraci√≥n de conexi√≥n\n",
    "# 'localhost' significa que el servidor est√° en tu propia m√°quina\n",
    "# '9696' es el puerto que definimos en app.run()\n",
    "URL_BASE = 'http://localhost:9696/predict/'\n",
    "\n",
    "# 2. Lista de modelos disponibles en la API\n",
    "# Estos coinciden con las rutas @app.route('/predict/lr'), etc.\n",
    "models = ['lr', 'svm', 'dt', 'knn']\n",
    "\n",
    "print(f\"Cliente configurado para conectar a: {URL_BASE}\")\n",
    "print(f\"Modelos a testear: {models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee169a",
   "metadata": {},
   "source": [
    "# 2: Definici√≥n de los Datos de Prueba\n",
    "\n",
    "Aqu√≠ definimos dos diccionarios de Python que representan a dos ping√ºinos con caracter√≠sticas muy distintas.\n",
    "\n",
    "- Ping√ºino 1: Caracter√≠sticas peque√±as (Isla Torgersen). Esperamos que sea Adelie.\n",
    "\n",
    "- Ping√ºino 2: Caracter√≠sticas grandes (Isla Biscoe). Esperamos que sea Gentoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9adc7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de prueba cargados en memoria.\n"
     ]
    }
   ],
   "source": [
    "# --- PING√úINO 1: Caracter√≠sticas peque√±as ---\n",
    "# Deber√≠a ser clasificado como 'Adelie'\n",
    "penguin_1 = {\n",
    "    'island': 'Torgersen',\n",
    "    'culmen_length_mm': 39.1,\n",
    "    'culmen_depth_mm': 18.7,\n",
    "    'flipper_length_mm': 181.0,\n",
    "    'body_mass_g': 3750.0,\n",
    "    'sex': 'MALE'\n",
    "}\n",
    "\n",
    "# --- PING√úINO 2: Caracter√≠sticas grandes ---\n",
    "# Deber√≠a ser clasificado como 'Gentoo'\n",
    "penguin_2 = {\n",
    "    'island': 'Biscoe',\n",
    "    'culmen_length_mm': 50.0,\n",
    "    'culmen_depth_mm': 15.0,\n",
    "    'flipper_length_mm': 220.0,\n",
    "    'body_mass_g': 5000.0,\n",
    "    'sex': 'FEMALE'\n",
    "}\n",
    "\n",
    "print(\"Datos de prueba cargados en memoria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac86aac",
   "metadata": {},
   "source": [
    "# 3: Petici√≥n al Servidor (Ping√ºino 1)\n",
    "\n",
    "Iteramos sobre la lista de modelos. Para cada uno, enviamos una petici√≥n POST con los datos del penguin_1 en formato JSON. Si el servidor responde con c√≥digo 200 (√âxito), mostramos la predicci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d5f071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üß™ TESTEANDO PING√úINO 1 (Probable Adelie) ---\n",
      "[LR]: {'model': 'Logistic Regression', 'species': 'Adelie'}\n",
      "[LR]: Predicci√≥n -> Adelie\n",
      "[SVM]: {'model': 'SVM', 'species': 'Adelie'}\n",
      "[SVM]: Predicci√≥n -> Adelie\n",
      "[DT]: {'model': 'Decision Tree', 'species': 'Adelie'}\n",
      "[DT]: Predicci√≥n -> Adelie\n",
      "[KNN]: {'model': 'KNN', 'species': 'Adelie'}\n",
      "[KNN]: Predicci√≥n -> Adelie\n"
     ]
    }
   ],
   "source": [
    "print(\"--- üß™ TESTEANDO PING√úINO 1 (Probable Adelie) ---\")\n",
    "\n",
    "for model_name in models:\n",
    "    # Construimos la URL espec√≠fica, ej: http://localhost:9696/predict/lr\n",
    "    full_url = URL_BASE + model_name\n",
    "    \n",
    "    try:\n",
    "        # Enviamos la petici√≥n POST\n",
    "        response = requests.post(full_url, json=penguin_1)\n",
    "        \n",
    "        # Verificamos si la respuesta fue exitosa\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"[{model_name.upper()}]: {result}\")\n",
    "            print(f\"[{model_name.upper()}]: Predicci√≥n -> {result['species']}\")\n",
    "        else:\n",
    "            print(f\"[{model_name.upper()}]: Error {response.status_code}\")\n",
    "            \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"‚ùå ERROR: No se pudo conectar a {full_url}\")\n",
    "        print(\"Aseg√∫rate de ejecutar 'python predict_app.py' en la terminal.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551cb59",
   "metadata": {},
   "source": [
    "# 4: Petici√≥n al Servidor (Ping√ºino 2)\n",
    "\n",
    "Repetimos el proceso para el segundo ping√ºino para verificar que los modelos distinguen entre clases diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8101ac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üß™ TESTEANDO PING√úINO 2 (Probable Gentoo) ---\n",
      "[LR]: {'model': 'Logistic Regression', 'species': 'Gentoo'}\n",
      "[LR]: Predicci√≥n -> Gentoo\n",
      "[SVM]: {'model': 'SVM', 'species': 'Gentoo'}\n",
      "[SVM]: Predicci√≥n -> Gentoo\n",
      "[DT]: {'model': 'Decision Tree', 'species': 'Gentoo'}\n",
      "[DT]: Predicci√≥n -> Gentoo\n",
      "[KNN]: {'model': 'KNN', 'species': 'Gentoo'}\n",
      "[KNN]: Predicci√≥n -> Gentoo\n"
     ]
    }
   ],
   "source": [
    "print(\"--- üß™ TESTEANDO PING√úINO 2 (Probable Gentoo) ---\")\n",
    "\n",
    "for model_name in models:\n",
    "    full_url = URL_BASE + model_name\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(full_url, json=penguin_2)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"[{model_name.upper()}]: {result}\")\n",
    "            print(f\"[{model_name.upper()}]: Predicci√≥n -> {result['species']}\")\n",
    "        else:\n",
    "             print(f\"[{model_name.upper()}]: Error {response.status_code}\")\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"‚ùå Error de conexi√≥n. El servidor parece estar apagado.\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cas-practic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
